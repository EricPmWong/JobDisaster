{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from psaw import PushshiftAPI\n",
    "import datetime \n",
    "from bs4 import BeautifulSoup \n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm, datasets\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter City (Emphasis on city) where natural disaster occured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchcity = 'dallas'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creates a list of URLS to search through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list=[]\n",
    "for page in range(1,6000):\n",
    "    url_list.append(\"https://api.adzuna.com:443/v1/api/jobs/us/search/\"+ str(page) +\"?app_id=d3330ea8&app_key=cbcbe79274381fae5af07fb6828067ce&results_per_page=100&where=\"+str(searchcity)+\"&sort_direction=up&sort_by=date&max_days_old=365\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starts pulling data from Adunza API for jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot = 1\n",
    "pulleddata = []\n",
    "for url in url_list:\n",
    "    try: \n",
    "        requests.get(url).json()['results'][0]\n",
    "        pulleddata.append(requests.get(url).json())\n",
    "        print(str(spot) + '0 job ads pulled')\n",
    "        spot += 1\n",
    "        time.sleep(1)\n",
    "    except: \n",
    "        print('This is the end of data')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structures data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structureddata = []\n",
    "for x in range(0, len(pulleddata)):\n",
    "    for y in pulleddata[x]['results']:\n",
    "        structureddata.append(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creates Dataframe and creates a saved file (in case of \"oopsies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for x in range(0, len(structureddata)):\n",
    "    try:\n",
    "        df['company'] = [structureddata[x]['company']['display_name'] for x in range(0, len(structureddata))]\n",
    "        df['date'] = [structureddata[x]['created'][:7] for x in range(0, len(structureddata))]\n",
    "        df['title']= [structureddata[x]['title']for x in range(0, len(structureddata))]\n",
    "        df['All_Sectors']= [structureddata[x]['category']['label']for x in range(0, len(structureddata))]\n",
    "\n",
    "    except:\n",
    "        print('error')\n",
    "        pass\n",
    "\n",
    "try: \n",
    "    df.drop_duplicates(inplace=True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing date to datetime data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null (all should be 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Data Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency of posting by dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most common Sectors posted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['All_Sectors'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Industry Dummyvariable DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industrygraphs = pd.get_dummies(df['All_Sectors'])\n",
    "industry = pd.concat([df, industrygraphs], axis=1)\n",
    "for x in industry.columns[6:]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saves Dataframe (with dummies, to cityname.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry.to_csv(str(searchcity)+'data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating of graphing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daterange = pd.date_range(start=\"2018-01\", end='2019-01', freq='M')\n",
    "graphme = pd.DataFrame(columns=[x for x in industry.columns[6:]], index= daterange)\n",
    "graphme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphme['2018-02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphme.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(6, (len(industry.columns))):\n",
    "    for date in industry[industry[str(industry.columns[x])] == 1]['date']:\n",
    "        for inde in graphme.index:\n",
    "            if str(date)[0:7] == str(inde)[:7]:\n",
    "                graphme[str(inde)[0:7]][str(industry.columns[x])]+=1\n",
    "graphme.to_csv(str(searchcity)+\"graphdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotly graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = {}\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "for num in range(0, (len(graphme))):\n",
    "    try:\n",
    "        traces['trace'+str(num)] = dict(\n",
    "                    x= graphme.index,\n",
    "                    y= graphme[graphme.columns[num]],\n",
    "                    mode='lines',\n",
    "                    name= graphme.columns[num])\n",
    "        print(name)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "data = [traces['trace'+str(x)] for x in range(0, (len(traces)))]\n",
    "\n",
    "plot({'data':data,\n",
    "       'layout' : {'title': str(searchcity) +\" Job searches for 2018\"},\n",
    "     }, filename=str(searchcity)+\"PLOTLY.html\")\n",
    "\n",
    "\n",
    "iplot({'data':data,\n",
    "       'layout' : {'title': str(searchcity) +\" Job searches for 2018\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,15))\n",
    "for num in range(6, len(industry.columns)):\n",
    "    sns.lineplot(data = graphme)\n",
    "plt.legend(labels=graphme.columns)\n",
    "plt.title(str(searchcity) + \" Job searches for 2018\")\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(searchcity)+\"Matplotlib.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
